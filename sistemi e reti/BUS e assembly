I BUS:

il BUS è un insieme di linee che conducono elettricità e ciascuna è collegata ad un PIN, ad esempio se due dispositivi da 32 piedini il BUS sarà formato da 32 linee, quindi la linea 1 collega i piedini 1 dei dispositivi ecc
ciascuna linea del BUS può trasferire al massimo un solo segnale per volta

ci sono due tipi di BUS:
interni alla CPU, porta dati verso e dell'ALU
esterni alla CPU, trasporta dati da e verso la memoria e i dispositivi I/O

il PROTOCOLLO dei BUS è un insieme di regole precise che consentono ai dispositivi di comunicare tra di loro, in poche parola il protocollo del BUS regola la trasmissione e la ricezione dei dati tramite un voltaggio

un dispositivo in grado di iniziare un trasferimento di dati si chiama master e uno che inizia la comunicazione a comando del master si chiama slave, però ci può essere solo un master alla volta, per questo viene istituita un'operazione chiamata arbitraggio

Il numero di linee di un BUS si chiama LARGHEZZA DEL BUS ed è relativa alle prestazioni, per aumentarle ci sono due tecniche:
1-Diminuzione del ciclo di BUS aumentando così il numero di bit passanti al secondo, però i segnali si muovono a velocità diverse quindi diventa incompatibile con modelli precedenti
2-Aumento della larghezza del BUS, ottenendo un numero maggiore di linee ma più lentezza(è il più diffuso)

recap prestazioni del BUS:
-bit rate: numero di bit al secondo che passano per il canale
-larghezza: numero di linee per la trasmissione dei dati
-velocità: frequenza del ciclo BUS
banda: numero massimo di byte al secondo passanti per il canale


BUS E SINCRONISMO

i BUS possono essere suddivisi in SINCRONI E ASINCRONI

BUS SINCRONO:

possiede in ingresso un segnale che deriva da un oscillatore che sincronizza le operazioni nella CPU
il segnale è un'onda generata dal clock
ha una struttura semplice ma con essa è difficile sfruttare a pieno le prestazioni dei dispositivi connessi

prendiamo ad esempio un ciclo in cui avviene la lettura:
l'operazione avviene in un numero definito di cicli clock, T1 e T2
1-in T1 la CPU attiva l'indirizzo leggere(segnale ADDRESS) dopo un tempo Tad
2-sempre in T1 dopo un tempo Tml si attiva il segnal MREQ(attivo basso) che attiva i chip di memoria, nello stesso istante viene attivato il segnale RD(read) nell CPU
3-in T2 la CPU attiva il segnale WAIT, se esso è basso allora significa che la memoria non ha ancora fatto nulla
4-In T3 la CPU verifica il segnale WAIT, se è alto allora il dato è disponibile sul BUS dati, la CPU allora lo legge e dopo degli istanti la CPU disattiva i segnali di attivazione MREQ e di lettura RD

segnali coinvolti:
-0: clock del bus
-ADDRESS: linee di indirizzo controllate dalla CPU
-DATA: BUS dei dati che vengono condivisi tra master e slave
-MREQ:segnale di controllo che eroga la CPU e indica il tipo di indirizzo(0=memoria, 1=dispositivo I/O)
-RD:il tipo di operazione richiesta dalla CPU(0=lettura, 1=scrittura)
-WAIT: linea generata dallo slave(0=attesa, 1=dato valido)

BUS ASINCRONO:

non ha un clock principale perciò ha una struttura semplice e sfrutta al massimo le prestazioni del dispositivo che lo utilizza
i suoi circuiti devono gestire l'MASYN(master synchronization) e SSYN(slave synchronization)

ad esempio un ciclo in cui avvine la lettura di un dato dalla RAM mediante un BUS Asincrono:
la lettura avviene grazie alla sincronizzazione tra master(CPU) e slave(memoria) ed è realizzata attraverso un FULL HANDSHAKE:
1-all'inizio la CPU attiva l'indirizzo della cella da dellgere(segnale ADDRESS)
2-la CPU informa la memoria che si tratta di una lettura(RD)
3-si attiva il segnale MSYN
4-quando il dato è disponibile la memoria attiva il segnle SSYN in seguito alla ricezione di MSYN
5-i segnale MSYN, RD e MREQ sono disattivati dalla CPU in seguito alla ricezione di SSYN


MSYN: attivato dal master quando è pronto a ricevere i dati e disattivato quando ha finito
SSYN:attivato dallo slave quando i dati sono belli caldi sul BUS e disattivato quando il master disattiva l'MSYN


ARBITRAGGIO DEL BUS

un'operazione di tre tipi:
1-arbitraggio centralizzato(daisy chaining a un livello)
2-arbitraggio centralizzato(daisy chaining con più livelli di priorità)
3-arbitraggio distribuito

ARBITRAGGIO CENTRALIZZATO A UN LIVELLO

l'accesso al BUS avviene attraverso un solo dispositivo alla volta ed è gestita dall'ARBITRO DEL BUS:
1-il dispositivo master attiva il BUS REQUEST
2-dopo l'arbitro attiva la linea BUS GRANT
3-BUS GRANT viene propagato in sequenza continua tra di dispositivi solo se quello dopo non ha attivato il BUS REQUEST
4-il dispositivo che ha attivato il BUS REQUEST deve attendere che si attivi la linea BUS GRANT per poter utilizzare il BUS

ARBITRAGGIO CENTRALIZZATO A PIU' LIVELLI:

la concessione dell'accesso al BUS avviene solo per un dispositivo ed è gestita dall'arbitro del BUS, proprio come prima:
1-ogni livello è indipendente e il funzionamento è uguale a ciò che ho descritto prima a parte che quando due o più linee BUS REQUEST sono attive nello stesso istante allora l'arbitro attiva il BUS GRANT al livello più basso(che ha quindi priorità maggiore)

ARBITRAGGIO DISTRIBUITO:

non esiste l'arbitro del BUS e i dispositivi si regolano da soli l'accesso al BUS:
1-il dispositivo master che vuole usare il BUS nega la linea ARBITRATION OUT
2-il dispositivo master che vuole usare il BU attende che la linea ARBITRATION IN si attivi e che la linea busy venga negata, così può attivare la linea busy e poi attiva la linea arbitration out e può così utilizzare il BUS
3-il master che utilizza il BUS nega la linea busy quando termina così da far sapere che la linea è di nuovo libera da usare 


I BUS Principali

I due principali sono:

system BUS o local BUS:
collega la CPU alla memoria del sistema ed è velcoe
PCI BUS o BUS di espansione:
molto lento e mette iin comunicazione le periferiche, si connettono al system BUS grazie ai chipset NorthBridge e SouthBRidge

periferiche Plug and Play

periferiche che possono essere collegate in qualunque momento
per funzionare hanno bisogno di:
-BIOS PnP:
software nel ROM che determina quando una periferica è connessa

-ESCD:
File che contiene tutte le informazioni necessarie per installare queste periferiche PnP

-Sistema operativo PnP:
è in grado di supportare la gestione dei driver per queste periferiche, ad esempio se inseriamo una periferica il BIOS se ne accorge e il sistema operativo completa l''installazione dei driver necessari
il sistema operativo esegue altri compiti come:
IRQ(interrupt request): segnala alla CPU di ogni comabiamento
DMA(Direct memory access): consete l'accesso alla memoria da parte di una periferica senza "disturbare la CPU"
Memory addresses: memoria assegnata per uso esclusivo ad alcune periferiche(es scheda video)
Configurazione I/O: definisce le porte di connessione attraverso le quali vengono inseriti i dispositivi


ARCHITETTURE NON VON NEUMANN

Col tempo le CPU e i sistemi di elaborazione sono migliorati un botto, ad esempio l'ampiezza di parola e di spazio di indirizzamento
ma ormai con le architetture Von Neumann si era arrivati ad un punto che non si poteva piu oltrepassare, quindi vengono inventate le Arch. Non Von Neumann atte ad aumentare la velocità di elaborazione a parità di frequenza del clock
ci sono diversi gradi di architetture:
SISD:single instruction single data)
SIMD(single instruction mult. data)
MISD:
MIMD: multiprocessori

Esecuzioni fuori ordine:

indica la capacità delle CPU di eseguire istruzioni senza necessariamente rispettare l'ordine del codice
può succedere che un risultato di una operazione serva per l'operazione successiva, impendendo così l'ordine parallelo, non si potrà dunque eseguire un operazione fuori ordine

Prefetch(precaricamento):

con questa tecnica i processori implementano delle unità che analizzando il codice cercano di prevedere quali dati serviranno al processore, può comportare degli errori, ad esempio se le instruzioni caricate dal microprocessore non vengono eseguite poi bisogna andare a cancellarle dalla memoria per poter mettere quelle giuste
questi problemi rendono difficile l'implemento delle istruzioni nell'hardaware senza un supporto del set di istruzioni, ma se questo è presente diventa tutto piu semplice

Speculative Execution: 

tecnica che permette di eseguire entrambi i rami preseni in un salto in modo da prevedere la direzione della diramazione

PIPELINE

significa catena di montaggio e indica la tecnica di passare al blocco successivo delle fasi non ancora completate
si compone in 5 passaggi:
IF(instruction fetch) lettura dell'istruzione
ID(instruction decode), decodifica dell'istruzione e prelievo degli operandi 
EX(execute), esecuzione dell'istruzione
MEM(memory), attivazione della memoria
WB(Write back), scrittura del risultato nel registro opportuno

in poche parole ste pipeline permettono di migliorare le prestazioni in ambito di velocità ma rendono piu complicata la struttura perchè c'è bisogno di 5 stadi in grado di collaborare tra loro
problematiche:
conflitti struttuali quando due fasi utilizzano contemporaneamente la stessa risorsa come alu o memoria RAM
conflitti tra i dati quando un'istruzione utilizza un dato ancora in elaborazione
conflitti di controllo quando le istruzioni che devono essere eseguite si trovano in un blocco in cui non dovrebbero essere, quindi va rifatto tutto da capo, perdendo tempo

si è trovata però una soluzione per risolvere queste criticità, cioè l'implementazione dello stallo, che consiste nel bloccare l'esecuzione delle istruzioni in attesa che il conflitto si risolvi, ma anche questo metodo rallenta il normale funzionamento

Per risolvere i conflitti strutturali si è aggiunto all'ALU l'unità FPU(floating point unit), che lavorano insieme
il conflitto tra dati viene risolto a livello software, il compilatore assembly implementa la funzione NOP(no operation) in cui ritarda l'esecuzione della seconda istruzione nel mentre aspetta l'adeguamento della pipeline
i conflitti di controllo sono difficili da risolvere in quanto si salti da un instruzioen all'altra vanno a previsione, infatti va prima aspettata la fase di execute

Tecnologie superscalari

servono a realizzare CPU con prestazioni sempre migliori, infatti permettono alla CPU di eseguire piu istruzioni durante un singolo ciclo clock

Brach prediction:

i salti condizionati influenzano negativamente la pipeline, infatti in sistemi x86 vengono eseguiti ogni 6 istruzioni circa, quindi è importante prevedere questo salto e caricare il giusto blocco di istruzioni nella pipeline


La cache memory

è una memoria di tipo statico(SRAM), e il loro uso è legato al comportamento delle applicazioni durante il loro utilizzo ed è caratterizzato da due principi di località:
-Località spaziale: i programmi in esecuzione possono accedere a celle di memoria in una zona gia definita oppure accedere a celle di memoria gia utilizzate
-Località temporale: il programma esegue le istruzini accedendo alle istruzioni subito successive a quella appena eseguita
 Se la memoria Cach aumenta otterremo un miglioramento delle istruzioni e inoltre la CPU ci accede in modo trasparent, quindi non diretto

ci sono diversi livelli di cache:
-cache integrata: dentro il processore(L1)
-cache interna: è collegata direttamente al processore ed è collegata alla CPU col BSB(L2)
-cache esterna: è sulla motherboard(L3)

la cache serve per istruzioni di lettura e scrittura ed è suddivisa in due sezioni(istruzioni e dati) ed è organizzata in blocchi di celle

per la scrittura la cache può essere usata in due modalità:
Cache Write Through: le operazioni di scrittura vengono eseguite sia nella cache che nella memoria centrale
Cache Write Back: le operazioni di scrittura vengono eseguite solo nella cache e invece viene scritta nella memoria solo quando viene sostituita

La cache è gestita tramite tre metodi: 
-diretto: a ciascun blocco di celle della memoria centrale viene associato un blocco uguale nella cache
-completamente associativo: ogni blocco può essere allocato in qualunque linea della cache 
-Associata a N vie: la cache è divisa in gruppi di  N linee

Memoria Virtuale:

grazie al componente MMU ,permette di far apparire la memoria centrale con più memoria rispetto a quella che ha realmente

DMA:

Direct Memory Access: permette al computer di spostare dati da un posto all'altro senza dover coinvolgere il processore principale



L'ISA X86

il microprocessore effettua le sue operazioni grazi ad un SET DI ISTRUZIONI 
I microporcessori si distringuono per queste caratteristiche:
-dimensione delle celle di memoria
-numero e tipi di registri interni
-ampiezza dei BUS
-dimensione delle istruzioni
e dal punto di vista strutturale e disiviso in tre blocchi:
-ALU: esegue le operazioni richieste dalla CPU
-i registri: general purpose e speciali: per memorizzare  temporaneamente i dati dei programmi, specialmente 3 tipi:
  -operandi
  -indici
  -indirizzi
-UC: stabilisce il ritmo in cui si susseguono le operazioni e collegato alla CPU genera i comandi eseguibili e il segnale di clock
registri speciali:
-IP(instruction pointer)
-SP(Stack pointer)
-IR(Instruction register)
-AR(consentono la segmentazione della memoria), CS,DS,ES,SS
-Registro dei flag: gruppo di bit che consentono di ottenere informazioni riguardanti il risultato dell'ultima operazione



Stack:
Indica un area di memoria collocata nella memoria centrale


IL LINGUAGGIO ASSEMBLY


significa assemblatore, e serve ad assemblare un porgramma scritto in codice macchina e per ogni codice operativo delle istruzioni di una CPU esiste una operazione in Assembly

in basso c'è il codice binario letto dall'hardware, poi sopra c'è questo codice rappresentato in esadecimale, poi sopra c'è Assembly x86 e altri  che rappresentano i linguaggi di basso livello , sopra ci sono i linguaggi di alto livello come C, C++, Pascal, poi in cima ci sono linguaggi di scripting interpretati come python, js, java

ogni istruzione assembly viene tradotta in una in linguaggio macchina e i comandi sono formati da tre lettere, ad esempio MOV, ADD, JMP


LA RETE INFORMATICA:

è un insieme di hardware, sofware e cablaggio che collaborando insieme permettono a piu dispositivi di comunicare tra loro
le reti hanno lo scopo di trasferire informazioni ad un gruppo di persone distribuita in un area piu o meno ampia
Le reti in cui i computer sono collegati tra loro nello stesso luogo sono chiamate reti locali o LAN

La connessione tra le reti si chiama networking e lo scambio di dati avviene tramite segnali sotto forma di binario
Le sorgenti o le destinazioni sono chiamati nodi terminali(end system o hosts) e gli altri nodi invece di commutazione

Tecnologia tasmissiva:
-reti broadcast: gli host sono direttamente collegati al canale di comunicazione, l'host invierà un pacchetto dati direttamente al destinatario inserendo il suo indirizzo, si parla di multicast se il messaggio viene inviato a piu destinatari
-reti punto a punto:gli host sono connessi tra loro a coppie e il acchetto deve seguire un path per arrivare a destinazione e spesso viene trovato con algoritmi di instradamento(routing)

Le reti possono essere classificate come:
LAN: computer collegati fisicamente in uno stesso luogo
MAN:all'interno di un grande centro urbano
WAN:collega diverse città o addirittura interi paesi
GAN:collegamento con tutto il mondo

Reti Locali:

reti private che solitamente collegano pc di un'organizzazione
hanno 3 caratteristiche:
-dimensione
-tecnologia trasmissiva
-topologia: la forma geometrica con la quale i vari host sono collegati tra loro:
  -Topologia a BUS: gli host solo collegati con un cavo fisico e si sincronizzano tramite una "collisione"
  -Topologia ad anello:gli host sono collegati ad anello e i dati vengono trasmessi a tutti e per poter trasmettere c'è bisogno di un token

Riguardo alla topologia alcune reti utilizzano la connessione punto a punto mentre altre a multipunto, quindi hanno accesso a piu nodi
-Reti a stella:numero di canali è uguale al numero di nodi meno 1, in caso di guasto di un canale tutta la rete è compromessa, al centro si trova l'hub/switch
-Reti ad anello:struttura circolare e se un nodo si guasta tutta la rete cade
-Reti a BUS:i computer sono tutti connessi ad un canale comune e solo uno alla volta può ricevere dati
-Reti a maglia:ogni computer è collegato a tutti gli altri, se ci sono motli nodi diventa molto complesso però anche vantaggioso
-Reti ad albero:tra due computer è presente un solo canale, ma se se ne guasta uno la rete non funziona piu, è vantaggioso perchè ha una struttura semplice e c'è un unico cammino per collegare gli host


Reti Geografiche:

in una WAN:
-insieme di host sui quali vengono eseguiti i programmi degli utenti
-un insieme di connessioni(subnet) che collega gli host tra loro e permette di inviare dati da un host sorgente a uno destinatario
ogni subnet è composta da:
-linea di trasmissione:il canale di comunicazione che puo essere in rame o fibra ottica o dall'etere(wireless)
-dispositivi di commutazione che permettono ai dati di spostarsi, ad esempio i repeater, i bridge e i router

Reti Wireless:

forma di connessione molto usata, ad esempio in casa o al lavoro
è una rete senza fili e prende il nome di wlan
reti PAN: reti a portata ridotta, ad esempio il bluetooth
La wlan sostituisce in molti posti di lavoro la rete cablata lan ed è nota anche come wifi e di solito per comunicare vengono usate onde radio a bassa fequenza, il router fornisce l'accesso alla rete ed è chiamato access point


TRASFERIMENTO DELL'INFORMAZIONE

lo scambio di pacchetti tra due dispositivi avviene tramite il canale di comunicazione che codifica i messaggi e li trasforma in segnali che possono essere elettrici o luminosi
due modalità di connessione:
-connection-oriented(esempio una telefonata)
1-Si apre la connessione
2-si trasferisci l'informazione
3-si chiude la sessione
-connectionless:
1-avviene in modo completamente autonomo(esempio servizio postale)

la tarsmissione dati può essere classificata in:
-simplex: in un solo senso come tarsmissioni televisive o radiofoniche
-half-duplex: in due sensi ma in tempi diversi, ad esempio il walkie talkie
-full-duplex: in due sensi contemporaneamente(ad esempio una chiamata telefonica)

I protocolli:

Per comunicare c'è bisogno di mettersi d'accordo trmaite dei protocolli che definiscono l'ordine e il formato dei messaggi inviati e ricevuti,
struttura a livelli per la comunicazione, all'interno del protocollo devono essere specificate la tipologia dei messaggi, le azioni che devono essere compiute per inviare i messaggi
i protocolli di comunicazione vengono anche chiamti protocolli di linea e devono essere rigidi durante la comunicazione tra macchine

Tecniche di trasferimento dell'informazione

nelle reti ci sono due tipi di risorse:
-trasmissive:il mezzo attraverso il quale avviene la comunicazione
-elaborative: i dispositivi necessari affinchè la comunicazione avvenga

Con modo di trasferimento si intendono le modalità (strategie) adottate dalla rete per permettere lo scambio di dati tra due applicazioni

multiplexing: serve a far si che piu appliazioni possano comunicare tra loro contemporaneamente sullo stesso canale
nella multiplazione statica il canale viene suddiviso in canali fisici
in quella dinamica avviene in base alle richieste quindi in tempo reale
